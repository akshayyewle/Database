{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DemoSession01</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2660d33f980>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('DemoSession01').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "|    10|\n",
      "|    11|\n",
      "|    12|\n",
      "|    13|\n",
      "|    14|\n",
      "|    15|\n",
      "|    16|\n",
      "|    17|\n",
      "|    18|\n",
      "|    19|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1000).toDF('number').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('tips.csv',header=True,inferSchema=True)\n",
    "\n",
    "print(type(df_pyspark))\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Head Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=10.34, tip=1.66, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=21.01, tip=3.5, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=23.68, tip=3.31, sex='Male', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=24.59, tip=3.61, sex='Female', smoker='No', day='Sun', time='Dinner', size=4),\n",
       " Row(total_bill=25.29, tip=4.71, sex='Male', smoker='No', day='Sun', time='Dinner', size=4)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Dataframe Schema/Info\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Dtypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total_bill', 'double'),\n",
       " ('tip', 'double'),\n",
       " ('sex', 'string'),\n",
       " ('smoker', 'string'),\n",
       " ('day', 'string'),\n",
       " ('time', 'string'),\n",
       " ('size', 'int')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Describe Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|summary|        total_bill|               tip|   sex|smoker| day|  time|              size|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|  count|               244|               244|   244|   244| 244|   244|               244|\n",
      "|   mean|19.785942622950824|2.9982786885245902|  NULL|  NULL|NULL|  NULL| 2.569672131147541|\n",
      "| stddev| 8.902411954856857|1.3836381890011815|  NULL|  NULL|NULL|  NULL|0.9510998047322347|\n",
      "|    min|              3.07|               1.0|Female|    No| Fri|Dinner|                 1|\n",
      "|    max|             50.81|              10.0|  Male|   Yes|Thur| Lunch|                 6|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Working With Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Select Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'total_bill'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['total_bill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|total_bill| tip|  time|\n",
      "+----------+----+------+\n",
      "|     16.99|1.01|Dinner|\n",
      "|     10.34|1.66|Dinner|\n",
      "|     21.01| 3.5|Dinner|\n",
      "|     23.68|3.31|Dinner|\n",
      "|     24.59|3.61|Dinner|\n",
      "|     25.29|4.71|Dinner|\n",
      "|      8.77| 2.0|Dinner|\n",
      "|     26.88|3.12|Dinner|\n",
      "|     15.04|1.96|Dinner|\n",
      "|     14.78|3.23|Dinner|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['total_bill','tip','time']).show(10)\n",
    "\n",
    "# Output Of Select Function is a PySpark Dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Add New Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Current Dataframe\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|Status|\n",
      "+----------+----+------+------+---+------+----+------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|   Yes|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|   Yes|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|   Yes|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|   Yes|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|   Yes|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|   Yes|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|   Yes|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|   Yes|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|   Yes|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|   Yes|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|   Yes|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|   Yes|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|   Yes|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|   Yes|\n",
      "+----------+----+------+------+---+------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding New Column With Constant Value\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn('Status',lit('Yes'))\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|Status|   daytime|\n",
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add New Column With Concatenation Of Values In Existing Columns\n",
    "from pyspark.sql.functions import concat, col\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn(\"daytime\", concat(col(\"day\"),lit('-'),col(\"time\")))\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|Status|   daytime|\n",
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|   Yes|Sat-Dinner|\n",
      "+----------+----+------+------+---+------+----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('New_Column').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rename Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------+---+------+----+------+----------+\n",
      "| bill| tip|   sex|smoker|day|  time|size|Status|   daytime|\n",
      "+-----+----+------+------+---+------+----+------+----------+\n",
      "|16.99|1.01|Female|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|10.34|1.66|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|21.01| 3.5|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|23.68|3.31|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|24.59|3.61|Female|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|25.29|4.71|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "| 8.77| 2.0|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|26.88|3.12|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|15.04|1.96|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|14.78|3.23|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|10.27|1.71|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|35.26| 5.0|Female|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|15.42|1.57|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|18.43| 3.0|  Male|    No|Sun|Dinner|   4|   Yes|Sun-Dinner|\n",
      "|14.83|3.02|Female|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|21.58|3.92|  Male|    No|Sun|Dinner|   2|   Yes|Sun-Dinner|\n",
      "|10.33|1.67|Female|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|16.29|3.71|  Male|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|16.97| 3.5|Female|    No|Sun|Dinner|   3|   Yes|Sun-Dinner|\n",
      "|20.65|3.35|  Male|    No|Sat|Dinner|   3|   Yes|Sat-Dinner|\n",
      "+-----+----+------+------+---+------+----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed(\"total_bill\", \"bill\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read New Dataset \n",
    "df = spark.read.csv('test2.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show Dataset\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop All Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop All Missing Values\n",
    "# Default Selection\n",
    "\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any\n",
    "\n",
    "df.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = all\n",
    "\n",
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any | \n",
    "# threshold = 1 (Atleast 1 non-null values)\n",
    "\n",
    "df.na.drop(how='any', thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any | \n",
    "# threshold = 2 (Min non-null values)\n",
    "\n",
    "df.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     NULL| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any | \n",
    "# threshold = 3 (Min non-null values)\n",
    "\n",
    "df.na.drop(how='any', thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any | \n",
    "# threshold = 4 (Min non-null values)\n",
    "\n",
    "df.na.drop(how='any', thresh=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how = any | \n",
    "# threshold = 4 (Min non-null values)\n",
    "\n",
    "df.na.drop(how='any',thresh=1,subset=['Name','age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Replace Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Mahesh| 18|      NULL| 40000|\n",
      "|     NULL| 34|        10| 38000|\n",
      "|     NULL| 36|      NULL|  NULL|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill Missing Values\n",
    "df.na.fill(18,['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|\n",
      "|     NULL|  34|        10| 38000|\n",
      "|     NULL|  36|      NULL|  NULL|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
      "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
      "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
      "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
      "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
      "|   Mahesh|NULL|      NULL| 40000|         28|                 5|         40000|\n",
      "|     NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|     NULL|  36|      NULL|  NULL|         36|                 5|         25750|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "        inputCols=['age','Experience','Salary'],\n",
    "        outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Filtering**\n",
    "\n",
    "- EQUAL (==)\n",
    "- NOT EQUAL TO (~)\n",
    "- AND (&)\n",
    "- OR (|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"test1.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Equal To**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Sunny| 29|         4| 20000|\n",
      "| Paul| 24|         3| 20000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Equal To\n",
    "df.filter(df['Salary'] == 20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Equal Or Greater Than\n",
    "df.filter(df['Salary'] >= 20000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Not Equal To**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~(df[\"Salary\"]==20000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple Filters With AND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"Salary\"]<20000) & (df[\"Salary\"]>15000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple Filters With OR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"Salary\"]>20000) | (df[\"Salary\"]<15000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Age\"],ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Grouping & Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"test3.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grouping & Aggregations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupedData[grouping expressions: [Name], value: [Name: string, Departments: string ... 1 more field], type: GroupBy]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(Salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summation of Salary by Name\n",
    "df.groupBy(\"Name\").sum(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|max(Salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      10000|\n",
      "|    Big Data|       5000|\n",
      "|Data Science|      20000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max Salary By Department\n",
    "df.groupBy('Departments').max('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(Salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Salary By Department\n",
    "df.groupBy('Departments').mean('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count By Department\n",
    "df.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aggregation Only** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **References**\n",
    "\n",
    "- https://github.com/krishnaik06/Pyspark-With-Python \n",
    "- https://www.youtube.com/watch?v=_C8kWso4ne4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
